# Mastering AI Basics: 종합 가이드

## 1. 기초 인공지능 및 머신러닝
- `AI`, `ML`, `DL`의 차이점은 무엇인가요?
- `지도학습`, `비지도학습`, `강화학습`은 각각 무엇이고 어떤 예시가 있나요?
- `기계학습`과 `딥러닝`은 어떻게 다른가요?
- 인공지능의 한계와 문제점은 무엇이며, 해결 방안은 무엇인가요?
- `과적합(overfitting)`이란 무엇이며 이를 방지하는 방법은?
- `학습률(learning rate)`이 중요한 이유는 무엇인가요?
- 모델의 `bias`와 `variance`는 무엇이며, 둘 사이의 `trade-off`는 무엇인가요?
- `정규화(Regularization)`란 무엇이며 `L1`과 `L2`의 차이는?
- `k-최근접 이웃(k-NN)` 알고리즘의 작동 원리는?
- `결정트리(Decision Tree)`의 학습 방식과 장단점은?
- `앙상블 학습(Ensemble Learning)`에는 어떤 방식이 있고, 장단점은?
- `K-평균 클러스터링(K-means)`의 작동 방식과 수렴 조건은?
- `차원 축소`는 왜 필요하며 어떤 기법(`PCA` 등)이 있나요?

## 2. 수학 / 통계 / 선형대수 기초
- `고유값(Eigenvalue)`, `고유벡터(Eigenvector)`는 무엇인가요?
- `PCA(주성분 분석)`의 수학적 개념과 활용 예시는?
- `SVD(특잇값 분해)`는 어떤 원리로 작동하며 어디에 활용되나요?
- `선형회귀(Linear Regression)`의 수식과 작동 원리는?
- `Gradient Descent`는 어떻게 작동하나요?
- `이항`, `정규`, `포아송` 분포의 차이점은?
- `기대값(Expected value)`과 `분산(Variance)`의 정의와 계산법은?
- `공분산(Covariance)`과 `상관계수(Correlation)`의 차이는?
- `MLE`, `MAP`의 차이는?
- `베이즈 정리(Bayes' Theorem)`란 무엇이며 적용 예시는?
- `중심극한정리(Central Limit Theorem)`란 무엇인가요?
- `샘플링(Random, Stratified)` 방식은 어떻게 다른가요?
- `Hypothesis Testing(가설검정)`은 어떤 절차로 이루어지나요?
- `신뢰구간(Confidence Interval)`의 의미는 무엇인가요?

## 3. 머신러닝 / 딥러닝 이론
- `SVM`의 개념과 작동 원리는?
- `Kernel Trick`이란 무엇이며, 고차원으로 어떻게 확장되나요?
- `Fully Connected Layer(FC)`의 구조와 역할은?
- 다양한 `활성함수(ReLU, Sigmoid, Tanh, GELU)`의 차이는?
- `Softmax 함수`는 어떤 문제에서 사용되며 어떤 특징이 있나요?
- `Backpropagation(역전파)`의 수학적 원리는?
- `Batch Normalization`의 작동 원리와 효과는?
- `Dropout`은 어떻게 작동하며 장단점은 무엇인가요?
- `SGD`, `Adam`, `RMSProp` 등 경사하강법의 변형들은 어떤 특징이 있나요?
- `Cross-Entropy Loss` 함수는 무엇인가요?
- `Cost function`과 `Objective function`의 차이는?
- `Accuracy`, `Precision`, `Recall`, `F1 Score`는 언제 사용하나요?
- `ROC Curve`, `AUC`는 어떤 지표이며 언제 중요한가요?

## 4. 딥러닝 구조 / 모델
- `RNN`의 구조와 한계는?
- `LSTM`은 `RNN`의 어떤 문제를 개선하나요?
- `GRU`는 `LSTM`과 어떻게 다른가요?
- `Attention 메커니즘`은 어떻게 작동하나요?
- `Transformer`의 기본 구조(`Encoder`, `Decoder`)는 어떻게 구성되나요?
- `Multi-head Attention`은 왜 필요한가요?
- `Positional Encoding`이 필요한 이유는?
- `Self-Attention`은 어떤 방식으로 작동하나요?
- `BERT`와 `GPT`는 어떤 구조적 차이를 가지고 있나요?
- `Encoder-only`, `Decoder-only`, `Encoder-Decoder` 구조의 차이는?
- `Residual Connection`은 왜 사용하며 어떤 효과가 있나요?
- `Layer Normalization`, `Batch Normalization`의 차이는?
- `ViT(Vision Transformer)`의 구조는?
- `U-Net`은 이미지 분할에서 어떻게 활용되나요?
- `Autoencoder`는 어떤 구성과 역할을 가지나요?
- `VAE(Variational Autoencoder)`는 어떻게 동작하나요?
- `GAN`의 `Generator`와 `Discriminator`는 각각 어떤 역할을 하나요?

## 5. 실전/응용/최신 트렌드
- `Self-supervised Learning`이란?
- `LLM(대형언어모델)`의 대표 모델과 특징은?
- `ChatGPT`는 `Transformer`와 어떤 관련이 있나요?
- `Fine-tuning`은 `Pre-training`과 어떻게 다른가요?
- `Zero-shot`, `One-shot`, `Few-shot` 학습이란?
- `Pruning`, `Quantization`, `Knowledge Distillation`은 어떤 원리로 경량화하나요?
- `Federated Learning`이란? 장단점은?
- `Diffusion Model`의 작동 원리는?
- `강화학습(Reinforcement Learning)`의 구성요소는?
- `Multi-agent Reinforcement Learning`은 어떤 분야에 활용되나요?
- `XAI(Explainable AI)`의 개념과 필요성은?
- `AI 윤리`에서 `편향`, `책임`, `설명가능성` 문제는?
- `비정형 데이터 분석`은 어떤 방식으로 수행되나요?
- `GNN(Graph Neural Network)`의 작동 원리는?
- `Data Augmentation(데이터 증강)`은 어떻게 수행되며 어떤 효과가 있나요?

## 6. 데이터 처리 파이프라인
- `결측치 처리`: 예시 - `다중대체법`
- `범주형 인코딩`: 예시 - `Target Encoding`
- `시계열 특징 추출`: 예시 - `FFT`
- `불균형 데이터 처리`: 예시 - `SMOTE-Tomek`

## 7. 최적화/튜닝
- 하이퍼파라미터 튜닝 기법: `Bayesian Optimization`, `Hyperband`
- `AutoML`이란 무엇이며, `Neural Architecture Search`는 어떻게 작동하나요?

## 8. AI 윤리/규제
- `Counterfactual Fairness`란?
- `Homomorphic 암호화`는 어떻게 개인정보를 보호하나요?
- `FDA AI 의료기기 승인`의 기준은?

## 9. 고급 학습 패러다임
- `메타러닝(Meta Learning)`이란? 예: `Reptile 알고리즘`
- `CLIP`은 멀티모달 학습에서 어떻게 작동하나요?

## 10. 산업별 적용
- `NU-Net`: `3D MRI` 분할에 어떻게 사용되나요?
- `LSTM-GAN`: 금융 시계열 데이터에 어떻게 적용되나요?
- `Digital Twin`: 제조업에서 어떻게 활용되나요?

## 11. 시스템 최적화
- `TensorRT`: 양자화는 어떻게 이루어지나요?
- `Feast`: MLOps에서의 `Feature Store` 역할은?
- `Evidently`: 모델 모니터링에서 어떤 기능을 제공하나요?

## 12. 수학 심화
- `Fokker-Planck 방정식`은 어떤 상황에서 사용되나요?
- `정보병목 현상(Information Bottleneck)`이란?

## 13. 신경과학 연계
- `BCI(Motor Imagery Decoding)`의 개념과 응용
- `SNN`, `Loihi 칩`은 어떤 원리로 작동하나요?

## 14. 차세대 컴퓨팅
- `양자 머신러닝(VQE 알고리즘)`은 무엇을 해결하나요?
- `Memristor 기반 인메모리 컴퓨팅`은 어떻게 동작하나요?

## 15. 실무 도구
- `MLflow`: 어떤 기능을 제공하나요?
- `Kubeflow`: 분산 학습 파이프라인에서의 역할은?
