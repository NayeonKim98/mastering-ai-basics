# Mastering AI Basics: 종합 가이드

## 1. 기초 인공지능 및 머신러닝

- ### AI, ML, DL의 차이점
AI(Artificial Intelligence)는 인간처럼 사고하고 학습하는 시스템 전체를 뜻합니다.
ML(Machine Learning)은 그중에서 데이터에서 직접 학습하는 알고리즘입니다.
DL(Deep Learning)은 머신러닝의 하위 분야로, 인공신경망(neural network) 기반의 복잡한 모델을 말합니다.
비유하자면, AI는 전체 ‘두뇌를 만드는 기술’, ML은 ‘두뇌를 훈련시키는 방법’, DL은 ‘뉴런 기반으로 훈련하는 방법’입니다.

- ### 기계학습과 딥러닝의 차이

기계학습은 특성(feature)을 사람이 정의하고, 모델이 그걸 이용해 학습합니다.
딥러닝은 이미지나 텍스트처럼 비정형 데이터(unstructured data) 에서도 스스로 특징을 추출합니다. 그래서 대규모 데이터와 연산 자원이 필요합니다.
즉, 기계학습은 사람이 가르쳐줘야 하고, 딥러닝은 스스로 눈치를 챕니다.

- ### 지도학습, 비지도학습, 강화학습의 차이와 예시

지도학습(Supervised Learning): 정답(label)이 있는 데이터를 학습합니다. 예: 스팸 메일 분류

비지도학습(Unsupervised Learning): 정답 없이 패턴을 찾습니다. 예: 고객 군집화(clustering)

강화학습(Reinforcement Learning): 보상을 기반으로 행동을 최적화합니다. 예: 알파고, 로봇 제어

마치 지도학습은 문제집 풀기, 비지도학습은 퍼즐 맞추기, 강화학습은 게임 깨기와 비슷합니다.

- ### 과적합(Overfitting)이란? 방지 방법은?

과적합은 학습 데이터엔 잘 맞지만, 새로운 데이터에는 성능이 나쁜 경우입니다.
훈련 데이터에 너무 집착해서 일반화를 못하는 상태입니다.

방지 방법: 데이터 증가 / Dropout / 조기 종료 /정규화 사용 등

과적합은 ‘시험범위만 외워서 실전 문제를 못 푸는’ 것과 같습니다.

- ### 정규화(Regularization)란? L1 vs L2 차이

정규화는 복잡한 모델을 억제해서 과적합을 줄입니다.

L1 정규화: 가중치의 절댓값을 합산 → 희소한 모델

L2 정규화: 가중치의 제곱합을 사용 → 전체 가중치를 고르게 줄임

L1은 ‘필요 없는 걸 없애고’, L2는 ‘전체를 다이어트’하는 느낌입니다.

- ### 앙상블 학습(Ensemble Learning)의 방식과 장단점

여러 모델을 결합해 더 좋은 성능을 내는 방식입니다.

주요 방식:

배깅(Bagging): 서로 다른 데이터를 학습 → 예: 랜덤 포레스트

부스팅(Boosting): 이전 오답을 보완하는 방식 → 예: XGBoost

스태킹(Stacking): 다른 모델의 결과를 메타 모델이 학습

장점: 일반화 성능 향상
단점: 해석 어려움, 느린 학습 시간

‘집단지성’의 효과지만, 설명력이 떨어지는 단점도 있어요.

- ### 학습률(Learning Rate)의 중요성

학습률은 가중치를 얼마나 빠르게 조정할지 결정하는 하이퍼파라미터입니다.

너무 크면: 발산하거나 최소값을 놓침

너무 작으면: 느리고, 지역 최소점에 머물 수 있음

학습률은 ‘공부 속도’입니다. 너무 빨라도, 느려도 안 됩니다.

- ### Bias vs Variance, Trade-off

Bias(편향): 단순한 모델이 생기는 오류.

Variance(분산): 복잡한 모델이 훈련 데이터에 과하게 반응하는 정도.

트레이드오프(Trade-off): 둘은 반비례합니다.
좋은 모델은 적당한 편향과 적당한 분산을 가져야 합니다.

편향은 ‘무지한 모델’, 분산은 ‘예민한 모델’입니다. 적절한 밸런스가 중요하죠.

- ## Algorithms

- ### `k-최근접 이웃(k-NN)` 알고리즘의 작동 원리는?

k-NN은 새로운 데이터가 주어졌을 때, 가장 가까운 k개의 이웃을 보고, 그 중 가장 많은 클래스로 분류합니다.
거리 측정은 일반적으로 유클리드 거리(Euclidean distance) 를 사용합니다.

마치 "친한 친구(k명)가 다 노란색이라면 나도 노란색"이라고 판단하는 방식이에요.

단점은 훈련이 빠르지만, 예측할 때마다 전체 데이터를 훑으므로 예측 속도가 느립니다.

- ### `결정트리(Decision Tree)`의 학습 방식과 장단점은?

결정트리는 데이터를 조건에 따라 계속 분기(split) 시키는 구조입니다.
어떤 조건으로 나눌지는 정보이득(Information Gain), 지니 지수(Gini Index) 같은 기준으로 선택합니다.

장점: 직관적, 해석이 쉬움, 수치형, 범주형 모두 처리 가능

단점: 쉽게 과적합됨, 작은 변화에 민감

결정트리는 '20질문 게임'처럼 "네가 날씨를 맞추고 싶으면, 비 왔어? 온도 어땠어?"처럼 질문을 던지는 구조입니다.

- ### `K-평균 클러스터링(K-means)`의 작동 방식과 수렴 조건은?

1. k개의 중심점을 무작위로 설정

2. 각 데이터를 가장 가까운 중심점에 할당

3. 중심점을 새롭게 계산 (평균값으로)

4. 중심점의 변화가 없을 때까지 반복

이 과정을 통해 클러스터 내 응집도(intra-cluster similarity)는 높고, 클러스터 간 분리는 극대화됩니다.

수렴 조건: 중심점이 변하지 않거나, 변화가 작을 때.

단점: 초기 중심에 따라 결과가 달라짐, 군집 수 k를 미리 알아야 함

마치 “k명의 리더가 있고, 구성원들이 가까운 리더를 따라가는” 과정이라고 보면 돼요.

- ### `차원 축소`는 왜 필요하며 어떤 기법(`PCA` 등)이 있나요?

고차원 데이터는 연산량이 크고, 시각화가 어려우며, 과적합 위험도 높습니다. 이를 차원 축소로 해결합니다.

대표 기법:

PCA(Principal Component Analysis): 분산이 큰 축을 따라 새로운 축을 잡아 투영합니다.

t-SNE, UMAP: 비선형적 구조를 시각화에 적합하게 줄여줌

차원 축소는 마치 "고해상도 이미지를 요약해서도 본질을 놓치지 않게 보는 기술"과 같아요.

- ### 인공지능의 한계와 문제점은 무엇이며, 해결 방안은 무엇인가요?

한계:

데이터 편향(Bias in Data)
설명 불가능성(Black-box)
윤리 문제(예: 사생활, 조작 가능성)
일반화 어려움

해결 방안:

공정성(fairness) 고려한 데이터 설계
XAI (설명 가능한 AI) 기법 도입
법적 윤리 기준 마련, 모델의 사후 검증(post-hoc verification)

AI는 똑똑하지만 "왜 그렇게 말했는지 설명 못 하는 천재"일 수 있어요. 이걸 보완하는 게 요즘 AI 윤리 흐름입니다.

## 2. 수학 / 통계 / 선형대수 기초

- `고유값(Eigenvalue)`, `고유벡터(Eigenvector)`는 무엇인가요?
- `PCA(주성분 분석)`의 수학적 개념과 활용 예시는?
- `SVD(특잇값 분해)`는 어떤 원리로 작동하며 어디에 활용되나요?
- `선형회귀(Linear Regression)`의 수식과 작동 원리는?
- `Gradient Descent`는 어떻게 작동하나요?
- `이항`, `정규`, `포아송` 분포의 차이점은?
- `기대값(Expected value)`과 `분산(Variance)`의 정의와 계산법은?
- `공분산(Covariance)`과 `상관계수(Correlation)`의 차이는?
- `MLE`, `MAP`의 차이는?
- `베이즈 정리(Bayes' Theorem)`란 무엇이며 적용 예시는?
- `중심극한정리(Central Limit Theorem)`란 무엇인가요?
- `샘플링(Random, Stratified)` 방식은 어떻게 다른가요?
- `Hypothesis Testing(가설검정)`은 어떤 절차로 이루어지나요?
- `신뢰구간(Confidence Interval)`의 의미는 무엇인가요?

## 3. 머신러닝 / 딥러닝 이론
- `SVM`의 개념과 작동 원리는?

SVM(Support Vector Machine)은 클래스 간 마진(margin)이 최대가 되는 결정 경계를 찾는 분류 알고리즘입니다.
가장 가까운 데이터 포인트는 서포트 벡터(Support Vector) 라고 부르며, 이들에 의해 경계가 결정됩니다.

비유하자면, SVM은 “두 그룹 사이에서 가장 넓은 길(마진)을 확보하는 담장”을 세우는 일입니다.

- `Kernel Trick`이란 무엇이며, 고차원으로 어떻게 확장되나요?

비선형 데이터를 고차원으로 매핑해서 선형적으로 분리되게 만드는 기법입니다.
하지만 실제로 고차원으로 올리지는 않고, 내적(inner product) 결과만 계산하는 게 핵심이죠.

마치 그림자(내적 값)만 보고 실제 모양은 보지 않는 ‘속임수(trick)’입니다.

- `Fully Connected Layer(FC)`의 구조와 역할은?

FC는 모든 뉴런이 서로 연결된 계층입니다. 입력값을 가중치와 곱하고 편향을 더한 후, 비선형 함수를 적용합니다.
주로 CNN의 마지막에 붙여 고차원 특징을 클래스에 매핑하는 데 쓰입니다.

- 다양한 `활성함수(ReLU, Sigmoid, Tanh, GELU)`의 차이는?

| 함수 | 특징 | 문제점 |
| --- | --- | --- |
| Sigmoid | 0~1사이, 확률적 해석 | 기울기 소실 |
| Tanh | -1~1 중심과 평균 0 | 여전히 기울기 소실 |
| ReLU | 0 이상만 전달, 계산 빠름 | 음수 죽음 |
| GELU | 입력에 따라 부드럽게 활성화 | 연산 복잡하지만 성능 좋음(BERT 등에서 사용) |

- `Softmax 함수`는 어떤 문제에서 사용되며 어떤 특징이 있나요?

다중 클래스 분류에서 확률처럼 출력되도록 만드는 함수입니다.
출력값의 합이 1이 되도록 정규화합니다.

마치 ‘가장 확률 높은 클래스를 뽑기 위한 투표기’입니다.

- `Backpropagation(역전파)`의 수학적 원리는?

역전파는 출력에서 입력 방향으로 오차를 전파하며, 각 가중치에 대한 기울기(gradient) 를 계산하는 방식입니다.
체인 룰(chain rule) 을 이용하여 각 층의 가중치를 업데이트할 수 있게 도와줍니다.

뒷문제 오답을 보고 앞단계 풀이 과정을 다시 고치는 수학 공부 방식 같아요.

- `Batch Normalization`의 작동 원리와 효과는?

각 층의 입력을 정규화(normalization) 하여 평균 0, 분산 1로 맞추고,
그 후 학습 가능한 스케일과 쉬프트 파라미터를 곱합니다.
이 덕분에 학습 안정성, 속도, 일반화가 향상됩니다.

마치 중간고사 성적을 반 평균에 맞춰서 재조정하는 느낌이에요.

- `Dropout`은 어떻게 작동하며 장단점은 무엇인가요?

학습 시 임의로 일부 뉴런을 비활성화해서 학습이 특정 뉴런에 의존하지 않도록 합니다.
앙상블 효과를 줘서 과적합을 방지합니다.

장점: 과적합 감소
단점: 학습 속도 저하, 테스트 시는 전체를 사용

- `SGD`, `Adam`, `RMSProp` 등 경사하강법의 변형들은 어떤 특징이 있나요?

| Optimizer | 특징 |
| --- | --- |
| SGD | 고전적 방식, 간단함, 노이즈 있음 |
| RMSProp | 학습률을 파라미터마다 조정(최근 기울기 제곱 기반) |
| Adam | 모멘텀 + RMSProp, 가장 널리 사용 (자동 기어 변속 같음) |

- `Cross-Entropy Loss` 함수는 무엇인가요?

예측 확률과 실제 정답 간 차이를 측정하는 손실 함수입니다.
확률값이 정답과 멀수록 큰 값을 가지며,
분류 문제에서 가장 널리 사용됩니다.

정답과 예측 간의 ‘불일치 정도’를 수치로 나타낸 거예요.

- `Cost function`과 `Objective function`의 차이는?

Cost Function: 하나의 예제에 대한 오차

Loss Function: 전체 데이터의 평균 오차

Objective Function: 최적화하고자 하는 전체 식 (정규화 포함)

- `Accuracy`, `Precision`, `Recall`, `F1 Score`는 언제 사용하나요?

| 지표 | 설명 | 사용 상황 |
| --- | --- | --- |
| Accuracy | 전체 중 맞춘 비율 | 클래스 비율 비슷할 때 |
| Precision | 양성 예측 중 실제 양성 비율 | False Positive가 중요할 때(예: 스팸 필터) |
| Recall | 실제 양성 중 맞춘 비율 | False Negative가 중요할 때(예: 암 진단) |
| F1 Score | 정밀도와 재현율의 조화 평균 | Precision과 Recall 균형이 필요할 때 |

- `ROC Curve`, `AUC`는 어떤 지표이며 언제 중요한가요?

ROC Curve와 AUC는 분류 모델의 성능을 평가할 때 사용하는 시각적 지표입니다.
특히 정확도(Accuracy) 만으로는 평가가 어려운, 불균형 데이터 상황에서 중요하게 사용돼요.

먼저 ROC Curve는 ‘Receiver Operating Characteristic Curve’의 줄임말로,
X축은 FPR(False Positive Rate), **Y축은 TPR(True Positive Rate, 즉 Recall)**을 나타냅니다.

이 커브는 모델의 임계값(threshold) 을 조금씩 조정해가며,
그때마다 나오는 FPR과 TPR의 쌍을 찍어서 만든 곡선이에요.
완벽한 모델이라면, FPR은 0에 가깝고 TPR은 1에 가까워서, 곡선이 좌상단 모서리에 가깝게 휘어집니다.

이때 AUC, 즉 ‘Area Under the Curve’는 이 ROC 곡선 아래 면적을 말하는데,
1에 가까울수록 좋은 모델이며, 0.5는 랜덤 추측 수준, 즉 아무 의미 없는 모델입니다.

이 지표의 진짜 매력은, 클래스 비율이 한쪽으로 몰려 있어도 비교적 안정적인 평가가 가능하다는 점이에요.
예를 들어, 암 진단처럼 양성이 드물지만 놓치면 안 되는 경우엔 Accuracy보다 ROC-AUC가 훨씬 신뢰할 수 있습니다.

또 하나 중요한 점은, 모델 전체의 분류 성향을 보여준다는 점입니다.
단순히 하나의 threshold에서 맞았는지만 보는 게 아니라,
모든 가능성에 대해 예측 능력을 평가하므로 모델의 전반적인 분류 성능을 직관적으로 볼 수 있습니다.

쉽게 말해, ROC Curve는 모델이 얼마나 ‘잘 구분하는지’를 시각적으로 보여주고,
AUC는 그 성능을 0~1 사이 숫자 하나로 요약해주는 지표라고 할 수 있어요.

## 4. 딥러닝 구조 / 모델

- ### `RNN`의 구조와 한계는?

RNN, 즉 Recurrent Neural Network는 순차적 데이터(sequence data) 를 처리하는 데 최적화된 딥러닝 구조입니다.
일반적인 인공신경망과 달리 RNN은 이전 시간의 출력을 다음 시간의 입력에 전달함으로써,
시간에 따른 문맥 정보(context) 를 기억하고 활용할 수 있는 게 특징입니다.

구조를 보면, 입력이 시퀀스로 주어졌을 때 각각의 시점에서 은닉 상태(hidden state) 를 업데이트하며,
이 은닉 상태가 다음 단계로 전달되기 때문에 내부적으로 일종의 메모리처럼 작동합니다.
예를 들어 자연어 처리에서 문장을 순서대로 입력했을 때, 앞 단어의 의미를 뒤 단어에 반영할 수 있는 구조죠.

하지만 RNN은 분명한 한계도 가지고 있습니다.
대표적으로 장기 의존성 문제(long-term dependency) 가 있어요.
즉, 입력 시점이 길어질수록 초기 정보가 뒤로 갈수록 희석되거나 소실되기 때문에,
문장 앞부분의 정보가 뒷부분에 제대로 전달되지 못하는 경우가 많습니다.

이 문제는 수학적으로 보면, 역전파 시 기울기(gradient)가 점점 작아져서 0에 수렴하는 vanishing gradient 문제로 설명됩니다.
이 때문에 긴 시퀀스를 학습하기엔 어려움이 많았고, 이를 해결하기 위해 나온 구조가 바로 LSTM과 GRU입니다.

결국 RNN은 순차적인 데이터를 처리하는 기본 뼈대는 제공하지만,
긴 문맥을 기억하는 데에는 구조적으로 한계가 있어서 개선형 구조가 필요하다는 점이 핵심입니다.

- ### `LSTM`은 `RNN`의 어떤 문제를 개선하나요?

LSTM, 즉 Long Short-Term Memory는 RNN의 가장 큰 단점인 장기 의존성 문제(long-term dependency) 를 해결하기 위해 고안된 구조입니다.
RNN은 순차 데이터를 처리할 수는 있었지만, 입력 시퀀스가 길어질수록 초기 정보가 소실되는 문제,
즉 vanishing gradient(기울기 소실) 현상이 심각했죠.

LSTM은 이 문제를 해결하기 위해, 기존 RNN의 구조를 크게 세 가지 게이트(Gate) 로 나누어 정보를 선택적으로 기억하거나 잊을 수 있도록 설계했습니다.

- LSTM의 주요 구성은 다음과 같습니다:
입력 게이트(Input Gate): 현재 입력을 얼마나 반영할지 결정

망각 게이트(Forget Gate): 과거 정보를 얼마나 잊을지 선택

출력 게이트(Output Gate): 어떤 정보를 다음 단계로 전달할지 결정

그리고 핵심이 되는 건 셀 상태(cell state) 라는 일종의 ‘정보 흐름 통로’입니다.
이 셀은 시그널을 시간 축을 따라 직접 전달하면서, 정보가 장기적으로 보존되도록 합니다.
게이트들을 통해 이 흐름을 통제하므로, 필요한 정보는 남기고, 불필요한 정보는 지웁니다.

결국 LSTM은 단순히 ‘기억을 잘하는 RNN’이 아니라,
기억해야 할 것과 버릴 것을 스스로 결정하는 똑똑한 구조로 진화한 형태입니다.

이런 특성 덕분에 LSTM은 챗봇, 기계번역, 음성인식 등 긴 문맥 정보를 필요로 하는 문제에 널리 사용되었고,
Transformer가 등장하기 전까지는 순차 처리의 최강자로 군림했던 모델이었습니다.

- ### `GRU`는 `LSTM`과 어떻게 다른가요?

GRU, 즉 Gated Recurrent Unit은 LSTM의 구조를 좀 더 간단하게 만든 개선형 RNN입니다.
핵심 목적은 LSTM처럼 장기 의존성 문제를 해결하면서도, 학습 속도를 높이고 계산 복잡도를 줄이는 것이에요.

우선 구조를 비교해보면,
LSTM은 세 개의 게이트와 셀 상태(cell state) 를 가지고 있지만,
GRU는 그걸 두 개의 게이트만으로 통합해 훨씬 단순화된 구조를 갖습니다.
구체적으로는 다음과 같습니다:

🧠 GRU의 구성:
Update Gate: 얼마나 과거 정보를 유지할지 결정 (LSTM의 입력 + 망각 게이트 역할 통합)

Reset Gate: 얼마나 과거 정보를 무시할지 결정

그리고 LSTM과 달리 별도의 셀 상태 없이, 은닉 상태(hidden state) 하나만을 사용합니다.
즉, 기억 셀과 은닉 상태를 하나로 합친 구조라고 할 수 있죠.

이로 인해 GRU는 LSTM보다 파라미터 수가 적고, 구조가 단순하므로 학습 속도가 빠르고 연산이 효율적입니다.
하지만 구조가 단순한 만큼, 복잡한 장기 의존성 문제에서는 성능이 살짝 떨어질 수 있습니다.

정리하자면, GRU는 “LSTM의 경량화 버전”이라고 볼 수 있으며,
데이터가 많지 않거나 학습 시간이 중요한 실무 상황에서 널리 사용되고 있습니다.

예를 들어, 음성 인식 앱이나 간단한 텍스트 생성기에서는 GRU가 훨씬 빠르고 충분히 좋은 성능을 보여줄 수 있어요.

- ### `Attention 메커니즘`은 어떻게 작동하나요?

Attention 메커니즘은 딥러닝, 특히 자연어 처리에서 입력 시퀀스의 모든 단어들 중 어떤 정보에 집중할지를 결정하는 기술입니다.
RNN이나 LSTM 같은 기존 구조는 순차적으로 정보를 처리하면서, 과거의 정보가 점점 희미해지는 장기 의존성 문제를 겪었어요.
Attention은 이를 해결하기 위해, 전체 입력을 한꺼번에 보면서 필요한 정보에 더 큰 가중치를 부여합니다.

🔍 핵심 아이디어는 "중요한 단어에 더 집중하자"는 것입니다.
예를 들어, “나는 사과를 좋아한다”라는 문장이 있을 때,
영어로 번역할 때 ‘사과(apple)’라는 단어를 번역할 시점에는,
앞뒤 문맥 중에서도 특히 ‘사과’라는 단어에 더 많은 가중치(attention weight) 를 줘야 하겠죠.

구체적으로는 다음 세 가지 벡터를 사용합니다:

Query (Q): 내가 지금 해석하려는 단어
Key (K): 각 입력 단어가 갖는 기준
Value (V): 실제 정보

Query와 Key의 유사도(점곱) 를 계산해서 중요도를 판단하고,
그 중요도(Score)를 Softmax로 정규화한 후, Value 벡터에 곱해 가중합을 구합니다.
이렇게 하면 중요한 단어일수록 더 크게 반영되고, 덜 중요한 단어는 작게 반영되죠.

쉽게 말해, Query는 “어떤 정보를 알고 싶어?”, Key는 “내가 그걸 줄 수 있을까?”,
그리고 Value는 “내가 가진 실제 정보야”라는 느낌이에요.

이 Attention 메커니즘은 RNN 없이도 문맥을 잘 반영할 수 있어서,
Transformer 모델, BERT, GPT 등 최근 거의 모든 SOTA 자연어 처리 모델의 핵심 구성 요소로 자리 잡게 되었습니다.

- ### `Transformer`의 기본 구조(`Encoder`, `Decoder`)는 어떻게 구성되나요?
- ### `Multi-head Attention`은 왜 필요한가요?
- ### `Positional Encoding`이 필요한 이유는?
- ### `Self-Attention`은 어떤 방식으로 작동하나요?
- ### `BERT`와 `GPT`는 어떤 구조적 차이를 가지고 있나요?
- ### `Encoder-only`, `Decoder-only`, `Encoder-Decoder` 구조의 차이는?
- ### `Residual Connection`은 왜 사용하며 어떤 효과가 있나요?
- ### `Layer Normalization`, `Batch Normalization`의 차이는?
- ### `ViT(Vision Transformer)`의 구조는?
- ### `U-Net`은 이미지 분할에서 어떻게 활용되나요?
- ### `Autoencoder`는 어떤 구성과 역할을 가지나요?
- ### `VAE(Variational Autoencoder)`는 어떻게 동작하나요?
- ### `GAN`의 `Generator`와 `Discriminator`는 각각 어떤 역할을 하나요?

## 5. 실전/응용/최신 트렌드
- `Self-supervised Learning`이란?
- `LLM(대형언어모델)`의 대표 모델과 특징은?
- `ChatGPT`는 `Transformer`와 어떤 관련이 있나요?
- `Fine-tuning`은 `Pre-training`과 어떻게 다른가요?
- `Zero-shot`, `One-shot`, `Few-shot` 학습이란?
- `Pruning`, `Quantization`, `Knowledge Distillation`은 어떤 원리로 경량화하나요?
- `Federated Learning`이란? 장단점은?
- `Diffusion Model`의 작동 원리는?
- `강화학습(Reinforcement Learning)`의 구성요소는?
- `Multi-agent Reinforcement Learning`은 어떤 분야에 활용되나요?
- `XAI(Explainable AI)`의 개념과 필요성은?
- `AI 윤리`에서 `편향`, `책임`, `설명가능성` 문제는?
- `비정형 데이터 분석`은 어떤 방식으로 수행되나요?
- `GNN(Graph Neural Network)`의 작동 원리는?
- `Data Augmentation(데이터 증강)`은 어떻게 수행되며 어떤 효과가 있나요?

## 6. 데이터 처리 파이프라인
- `결측치 처리`: 예시 - `다중대체법`
- `범주형 인코딩`: 예시 - `Target Encoding`
- `시계열 특징 추출`: 예시 - `FFT`
- `불균형 데이터 처리`: 예시 - `SMOTE-Tomek`

## 7. 최적화/튜닝
- 하이퍼파라미터 튜닝 기법: `Bayesian Optimization`, `Hyperband`
- `AutoML`이란 무엇이며, `Neural Architecture Search`는 어떻게 작동하나요?

## 8. AI 윤리/규제
- `Counterfactual Fairness`란?
- `Homomorphic 암호화`는 어떻게 개인정보를 보호하나요?
- `FDA AI 의료기기 승인`의 기준은?

## 9. 고급 학습 패러다임
- `메타러닝(Meta Learning)`이란? 예: `Reptile 알고리즘`
- `CLIP`은 멀티모달 학습에서 어떻게 작동하나요?

## 10. 산업별 적용
- `NU-Net`: `3D MRI` 분할에 어떻게 사용되나요?
- `LSTM-GAN`: 금융 시계열 데이터에 어떻게 적용되나요?
- `Digital Twin`: 제조업에서 어떻게 활용되나요?

## 11. 시스템 최적화
- `TensorRT`: 양자화는 어떻게 이루어지나요?
- `Feast`: MLOps에서의 `Feature Store` 역할은?
- `Evidently`: 모델 모니터링에서 어떤 기능을 제공하나요?

## 12. 수학 심화
- `Fokker-Planck 방정식`은 어떤 상황에서 사용되나요?
- `정보병목 현상(Information Bottleneck)`이란?

## 13. 신경과학 연계
- `BCI(Motor Imagery Decoding)`의 개념과 응용
- `SNN`, `Loihi 칩`은 어떤 원리로 작동하나요?

## 14. 차세대 컴퓨팅
- `양자 머신러닝(VQE 알고리즘)`은 무엇을 해결하나요?
- `Memristor 기반 인메모리 컴퓨팅`은 어떻게 동작하나요?

## 15. 실무 도구
- `MLflow`: 어떤 기능을 제공하나요?
- `Kubeflow`: 분산 학습 파이프라인에서의 역할은?
