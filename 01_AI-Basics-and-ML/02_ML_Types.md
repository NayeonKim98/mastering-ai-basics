# ML의 종류 : 지도학습, 비지도학습, 강화학습

<br>

## 1. 지도학습(Supervised Learning)
- 지도(指導) : 누가 가르쳐 준다.
- 핵심 개념 : 데이터마다 정답이 함께 주어짐.
- 모델은 그 정답을 잘 예측하는 방향으로 학습

- 수학적 이해 : 입력값 X와 출력값 Y를 주면 둘을 잇는 함수f(x)를 찾는게 목적

- 비유 : "이 사진은 강아지야." 라고 지도해주는 선생님이 있는 것. 정답이 있으니 채점도 되고 오답에 대한 교정도 가능

- 대표 예시:
    - 분류 문제(classification) : 스팸메일 판별, 암 진단(양성/음성), 손글씨가 어떤 글자인지 판별
    - 회귀 문제(regression) : 아파트 가격 예측, 주식 가격 예측
    - KNN : 새로운 데이터가 들어오면 주변 이웃(k개)의 라벨을 참조해 예측값을 정함. 주변에 무궁화가 많으면 새로 들어온 애도 무궁화.

<br>

## 2. 비지도학습(Unsupervised Learning)
- 스스로 배워라. 정답이 없는 데이터 속에서 구조나 패턴을 발견하는 것이 목표
- 핵심 개념 : Label이 없음.

- 수학적 이해 : 그냥 X만 던져줌.

- 비유 : 새 학기 반에 딱 들어갔을 때, 아직 누가 친한지도 모를 때, 스타일이나 말투 등을 통해 "아, 쟤네 둘은 친구인가보다." 하는 그런 감(Clustering과 유사)

- 대표 예시:
    - 군집화(Clustering): 고객 유형 분류 (VIP, 일반 고객)
    - 차원 축소(dimensinality reduction): 이미지 압축, 노이즈 제거
    - 연관 규칙 학습 : 상품 구매 패턴에서 연관 규칙을 찾는 마켓 바스켓 분석
    - K-means : 단지 데이터를 비슷한 애들끼리 묶어주는 군집화(clustering)

<br>

## 3. 강화학습(Reinforcement Learning)
- 보상을 통해 학습하는 방식. 
- 행동(action)을 하면 환경(Environment)이 보상(Reward)을 주고, 그걸 학습에 반영
- 보상을 최대화하는 `정책(policy)`을 찾는게 목표
* `정책(policy)` : 각 상황에서 어떤 행동을 선택할지 결정하는 전략
- 핵심 개념 : Agent(행위자)가 환경과 상호작용하며 학습

- 수학적 이해 : Markov Decision Process(`MDP`)를 기반으로 함.

* `MDP` : 미래 상태가 오직 현재 상태에만 의존한다. 과거의 정보는 중요하지 않고, 현재 상태(state)로 다음 행동(action)을 결정.

- 비유 : 강아지에게 "앉아!" 라고 했을 때, 잘 앉으면 간식(보상)을 주는 것과 같음. 반복 훈련을 통해 강아지는 간식을 최대한 많이 받는 전략을 배우게 됨.

- 대표 예시:
    - 알파고 : 바둑에서 승리할 때 보상
    - 게임 플레이 : 목표 점수를 높이는 전략
    - 주식 자동 매매 : 이익을 극대화하는 매매 전략
    - 로봇이 장애물을 피하며 목적지까지 이동하는 법 학습

<br>

### 머신러닝 학습방식 3종 비교표

| 학습 방식 | 정의 | 비유 | 대표 알고리즘 | 예시 |
|-----------|------|------|----------------|------|
| **지도학습** (Supervised) | 정답(label)이 있는 데이터를 학습 | 선생님이 정답지를 주며 문제 풀이 | 선형 회귀, SVM, KNN, 결정트리, CNN | 스팸 분류, 암 진단, 손글씨 분류 |
| **비지도학습** (Unsupervised) | 정답 없이 구조나 패턴을 발견 | 친구 관계 없이 친한 무리 추측 | K-평균, DBSCAN, PCA, Autoencoder | 고객 세그먼트, 뉴스 분류, 이미지 압축 |
| **강화학습** (Reinforcement) | 보상을 통해 최적의 행동을 학습 | 강아지가 간식으로 훈련 받는 것 | Q-learning, DQN, Policy Gradient | 알파고, 게임 AI, 자율주행, 로봇 제어 |