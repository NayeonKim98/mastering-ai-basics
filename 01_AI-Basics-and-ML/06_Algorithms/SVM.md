# SVM (Support Vector Machine)

<br>

## 핵심 개념

- 데이터를 분류하기 위해 가장 margin이 넓은 경계선을 찾는 알고리즘
- 단순한 분류기이지만, 비선형 문제도 `커널 기법`으로 해결 가능

    - ### 커널 트릭 (Kernel Trick)
        
        - 데이터를 선형 분리 불가능한 경우
        - 고차원 공간으로 매핑해서 선형 분리를 가능하게 함
        - 데이터가 평면(2D)에 있을 때는 선형으로 나누기 어려울 수 있는데, 커널을 3차원으로 만드는 것. 
        - 비유 : 칠판의 고무자석. 고무판을 우그러뜨리면 처음에 뒤섞여있던 빨간색/파란색 자석들이 서로 위아래로 떨어져 직선 하나로 나눌 수 있게 되는 상황과 비슷
        <br>

        | 커널 종류 | 설명 |
        | --- | --- |
        | 선형 커널 | 일반적인 직선 기준 |
        | RBF(가우시안) 커널 | 데이터가 동그랗게 뭉친 경우 좋음 |
        | 다항식 커널 | 비선형 경계가 필요한 경우 |

        <br>
        - 예시 코드:

        ```python
        from sklearn.svm import SVC

        # 데이터: (점수, 수면시간), 레이블은 '합격/불합격'
        X = [[70, 6], [80, 7], [90, 6], [40, 8], [50, 7]]
        y = ['합격', '합격', '합격', '불합격', '불합격']

        # 모델: 커널은 선형(linear)
        model = SVC(kernel='linear')
        model.fit(X, y)

        print(model.predict([[65, 6]]))  # 출력: ['합격'] or ['불합격']
        ```

- 비유 : 학생들을 줄세우는데, 각 반의 가장 키 큰 학생들 사이에 선을 긋는 방식. 즉, **두 집단의 사이 간격을 최대한 넓히는 선(결정 경계)를 그린다!**

<br>

## 작동 원리

1. 데이터를 분류하기 위해 결정 경계(Hyperplane)를 찾음
2. 가장 가까운 데이터(Support Vectors)와의 거리(Margin)를 최대화
3. 선형 분리가 어려울 경우, 커널 함수를 사용해 고차원 공간으로 변환

### 과정 정리

1. 초평면 정의
    - 2차원 : 선
    - 3차원 : 평면
    - n차원 : 초평면

2. 서포트 벡터 찾기
    - 경계와 가장 가까운 점들(모델 결정에 핵심 역할)

3. 마진 최대화
    - 두 클래스 사이의 가장 큰 여유 공간 확보

<br>

## 수학적 표현

- 결정 경계는 다음과 같은 선형 함수로 표현
    - f(x) = w^Tx + b = 0
    
    - w : 가중치 벡터 (선의 기울기)
    - b : 절편(bias)
    - | w^Tx + b |가 클수록 분류의 확신도가 높음

    - 최적화 문제로 바뀜. margin을 최대화하면서 제약조건을 만족하는 w, b를 찾는 문제.
        - 마진을 최대화 = |w|를 최소화

<br>

## SVM의 장단점

| 장점 | 단점 |
| --- | --- |
| 고차원 데이터에서도 효과적 | 느림(특히 데이터 양 많을 때) |
| 마진 기반으로 일반화 성능 좋음 | 파라미터 튜닝 필요 (C, 커널 등) |
| 다양한 커널로 비선형 문제 해결 가능 | 해석이 어려움(트리처럼 시각화 힘듦) |

<br>

## 관련 개념

| 용어 | 설명 |
| --- | --- |
| 마진(Margin) | 결정 경계와 가장 가까운 데이터 사이의 거리 |
| 서포트 벡터 | 마진에 닿아 있는 데이터 포인트 |
| 커널 함수 | 고차원 공간으로 데이터를 옮기는 방법 |
| C값 | 오차 허용 정도(오차에 얼마나 민감할지) -> 작으면 마진 중시, 크면 오차 최소화 중시 |
